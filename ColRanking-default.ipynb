{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "using PyPlot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "srand(1)\n",
    "\n",
    "# number of users\n",
    "d1 = 40;\n",
    "\n",
    "# number of items\n",
    "d2 = 60;\n",
    "\n",
    "# number of observations\n",
    "n = 10000;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# generate the hidden ratings\n",
    "ThetaS = rand(d1,4) * rand(4,d2)\n",
    "\n",
    "# Need to have the sum of rows equaling 0\n",
    "for i = 1:d1\n",
    "    ThetaS[i,:] -= mean(ThetaS[i,:])\n",
    "end\n",
    "\n",
    "# Need to make the Frobenius norm <= 1\n",
    "ThetaS = ThetaS / vecnorm(ThetaS);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y = []\n",
    "X = []\n",
    "P = []\n",
    "\n",
    "for i = 1:n\n",
    "    Xi = zeros(d1, d2)\n",
    "    \n",
    "    lin = rand(1:d1)\n",
    "    c1 = rand(1:d2)\n",
    "    c2 = rand(1:d2)\n",
    "    while c2 == c1\n",
    "        c2 = rand(1:d2)\n",
    "    end\n",
    "    \n",
    "    Xi[lin,c1] = 1\n",
    "    Xi[lin,c2] = -1\n",
    "    Xi = Xi * sqrt(d1 * d2)\n",
    "    \n",
    "    push!(X, Xi)\n",
    "    push!(P, [lin, c1, c2])\n",
    "    \n",
    "    if ThetaS[lin,c1] > ThetaS[lin,c2]\n",
    "        push!(y, 1)\n",
    "    else\n",
    "        push!(y, 0)\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nucNorm (generic function with 1 method)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function nucNorm(A)\n",
    "    return sum(svd(A)[2])\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "adjust (generic function with 1 method)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make sure the matrix's rows are centered\n",
    "\n",
    "function adjust(X)\n",
    "    ans = copy(X)\n",
    "    \n",
    "    for i = 1:size(X)[1]\n",
    "        ans[i,:] -= mean(ans[i,:])\n",
    "    end\n",
    "    \n",
    "    return ans\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "obj (generic function with 1 method)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The objective function\n",
    "\n",
    "function obj(Theta, ns)\n",
    "    ans = 0\n",
    "    \n",
    "    for i = 1:ns\n",
    "        t = sqrt(d1 * d2) * (ThetaS[P[i][1], P[i][2]] - ThetaS[P[i][1], P[i][3]])\n",
    "#         t = trace(Theta' * X[i])\n",
    "        ans = ans + log(1 + e^t) - y[i] * t\n",
    "    end\n",
    "    \n",
    "    return ans / ns\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "deltaF (generic function with 1 method)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute the derivative of the objective loss\n",
    "# Theta is our current guess\n",
    "# numSamples represents the number of X's we are considering\n",
    "\n",
    "function deltaF(Theta, ns)\n",
    "    \n",
    "    ans = zeros(d1,d2)\n",
    "    \n",
    "    for i = 1:ns\n",
    "        tr = sqrt(d1 * d2) * (ThetaS[P[i][1], P[i][2]] - ThetaS[P[i][1], P[i][3]])\n",
    "        ans = ans + (e^tr / (1 + e^tr) - y[i]) * X[i]\n",
    "    end\n",
    "    \n",
    "    return ans / ns\n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "prox (generic function with 1 method)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The proximal function\n",
    "# return the matrix X that minimizes lambda * ||X||_nuc + 1/(2 lambda_k) || X - V ||_F^2\n",
    "# equivalent to (lamda*lambda_k) ||X||_nuc + 1/2 || X - V ||_F^2\n",
    "\n",
    "function prox(lambda, V)\n",
    "    \n",
    "    A,S,B = svd(V)\n",
    "    S = max(S - lambda, 0)\n",
    "    \n",
    "    return adjust(A * diagm(S) * B')\n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "checkKKT (generic function with 1 method)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function checkKKT(lamb, Theta, ns)\n",
    "    println(\"Checking KKT conditions\")\n",
    "    \n",
    "    tot = 0\n",
    "    \n",
    "    for i = 1:ns\n",
    "        tr = sqrt(d1 * d2) * (ThetaS[P[i][1], P[i][2]] - ThetaS[P[i][1], P[i][3]])\n",
    "        tot = tot + (e ^ tr / (1 + e ^ tr) - y[i]) * X[i]\n",
    "    end\n",
    "    \n",
    "    tot = tot / ns\n",
    "    \n",
    "    U,S,V = svd(Theta)\n",
    "    k = rank(Theta)\n",
    "    U = U[:,1:k]\n",
    "    V = V[:,1:k]\n",
    "    \n",
    "    tot = tot + lamb * U * V'\n",
    "    \n",
    "    println(\"norm = \", norm(tot), \"    lambda = \", lamb)\n",
    "#     if norm(tot) <= lambda\n",
    "#         println(\"GOOD - the norm is smaller than lambda\")\n",
    "#     else\n",
    "#         println(\"OOPS - the norm is greater than lambda\")\n",
    "#     end\n",
    "    \n",
    "    println(norm(U' * tot))\n",
    "    \n",
    "    println(norm(tot * V))\n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### As a sanity check, make sure that our gradient steps indeed decreases obj loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden loss 0.3460187365116856\n",
      "Current loss 0.3460187365116856\n",
      "Loss after 1 steps: 0.3460187365116856\n",
      "Loss after 2 steps: 0.3460187365116856\n",
      "Loss after 3 steps: 0.3460187365116856\n",
      "Loss after 4 steps: 0.3460187365116856\n",
      "Loss after 5 steps: 0.3460187365116856\n",
      "  1.049107 seconds (1.98 M allocations: 1.825 GB, 32.99% gc time)\n"
     ]
    }
   ],
   "source": [
    "Theta = adjust(rand(d1,d2))\n",
    "\n",
    "println(\"Hidden loss \", obj(ThetaS, n))\n",
    "println(\"Current loss \", obj(Theta, n))\n",
    "\n",
    "@time for stp = 1:5\n",
    "    alpha = 1.0\n",
    "\n",
    "    newTheta = Theta - alpha * deltaF(Theta, n)\n",
    "    newTheta = adjust(newTheta)\n",
    "\n",
    "    println(\"Loss after \", stp, \" steps: \", obj(newTheta, n))\n",
    "    \n",
    "    Theta = copy(newTheta)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We'll pick a specific number of samples in terms of n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "numSamples = []\n",
    "for den = [3,2,1.5,1]\n",
    "    push!(numSamples, convert(Int64, floor(n / den)))\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Let's test out the algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working with 3333 samples\n",
      "at iteration 25\n",
      "at iteration 50\n",
      "at iteration 75\n",
      "at iteration 100\n",
      "at iteration 125\n",
      "at iteration 150\n",
      "at iteration 175\n",
      "at iteration 200\n",
      "f + g = 0.45146378760514205\n",
      "f = 0.34505227160796126\n",
      "g = 0.10641151599718081\n",
      "Loss = 0.47027365008949334\n",
      "\n",
      "Checking KKT conditions\n",
      "norm = 0.12907085835657434    lambda = 0.15\n",
      "0.07129749815556441\n",
      "0.07129749815556441\n",
      "\n",
      "  9.476296 seconds (14.54 M allocations: 24.324 GB, 20.65% gc time)\n",
      "\n",
      "\n",
      "working with 5000 samples\n",
      "at iteration 25\n",
      "at iteration 50\n",
      "at iteration 75\n",
      "at iteration 100\n",
      "at iteration 125\n",
      "at iteration 150\n",
      "at iteration 175\n",
      "at iteration 200\n",
      "f + g = 0.4444724337310466\n",
      "f = 0.344268185227342\n",
      "g = 0.10020424850370462\n",
      "Loss = 0.4515376597499117\n",
      "\n",
      "Checking KKT conditions\n",
      "norm = 0.11617045023985854    lambda = 0.15\n",
      "0.0671385249606058\n",
      "0.06713852496060578\n",
      "\n",
      " 12.621242 seconds (21.71 M allocations: 36.442 GB, 19.63% gc time)\n",
      "\n",
      "\n",
      "working with 6666 samples\n",
      "at iteration 25\n",
      "at iteration 50\n",
      "at iteration 75\n",
      "at iteration 100\n",
      "at iteration 125\n",
      "at iteration 150\n",
      "at iteration 175\n",
      "at iteration 200\n",
      "f + g = 0.44537186982977095\n",
      "f = 0.3439294162209568\n",
      "g = 0.10144245360881417\n",
      "Loss = 0.4421686551577257\n",
      "\n",
      "Checking KKT conditions\n",
      "norm = 0.10672332866292925    lambda = 0.15\n",
      "0.06796814312148315\n",
      "0.06796814312148317\n",
      "\n",
      " 25.187575 seconds (29.14 M allocations: 48.563 GB, 24.97% gc time)\n",
      "\n",
      "\n",
      "working with 10000 samples\n",
      "at iteration 25\n",
      "at iteration 50\n",
      "at iteration 75\n",
      "at iteration 100\n",
      "at iteration "
     ]
    }
   ],
   "source": [
    "overallLF = []\n",
    "\n",
    "final = copy(ThetaS)\n",
    "\n",
    "@time for ns = numSamples\n",
    "    LF = []\n",
    "    \n",
    "    println(\"working with \", ns, \" samples\")\n",
    "    \n",
    "    curTheta = zeros(d1,d2)\n",
    "    lambda = 0.15   # the regularization parameter\n",
    "    lambda_k = .05   # the step size\n",
    "    diff = lambda_k - lambda_k / 5\n",
    "    \n",
    "    maxit = 200\n",
    "    @time for steps = 1:maxit\n",
    "        lambda_k = lambda_k - 0 / maxit\n",
    "        \n",
    "        # first, go in the direction of f\n",
    "        V = curTheta - lambda_k * deltaF(curTheta, ns)\n",
    "        \n",
    "        # now, perform the proximal step\n",
    "        newTheta = prox(lambda * lambda_k, V)\n",
    "\n",
    "        # some information about runs\n",
    "        if steps % 25 == 0 || steps == maxit\n",
    "            println(\"at iteration \", steps)\n",
    "            \n",
    "            if steps == maxit\n",
    "                println(\"f + g = \", obj(curTheta, ns) + lambda * nucNorm(curTheta))\n",
    "                println(\"f = \", obj(curTheta, ns))\n",
    "                println(\"g = \", lambda * nucNorm(curTheta))\n",
    "                println(\"Loss = \", vecnorm(ThetaS - newTheta)^2)\n",
    "                println()\n",
    "                checkKKT(lambda, newTheta, ns)\n",
    "                println()\n",
    "                \n",
    "                final = copy(newTheta)\n",
    "            end\n",
    "        end\n",
    "\n",
    "        # update the loss array\n",
    "        push!(LF, vecnorm(ThetaS - newTheta)^2)\n",
    "        \n",
    "        # if I hit the max number of steps, stop anyway\n",
    "        if steps == maxit\n",
    "            push!(overallLF, vecnorm(ThetaS - newTheta)^2)\n",
    "        end\n",
    "        \n",
    "        # update Theta for the next iteration\n",
    "        curTheta = copy(newTheta)\n",
    "    end\n",
    "    \n",
    "#     dims = convert(Int64, (d1+d2)/2)\n",
    "#     filename = string(\"./data/\", dims, \"-\", ns, \".txt\")\n",
    "#     writedlm(filename, LF)\n",
    "    \n",
    "    println()\n",
    "    println()\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# writedlm(string(\"./data/\", convert(Int64, (d1+d2)/2), \"-final.txt\"), overallLF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plotting the loss function\n",
    "plot(numSamples, overallLF)\n",
    "xlabel(\"Number of observations\", size=15)\n",
    "ylabel(\"Loss\", size=15)\n",
    "axes()[:tick_params](\"y\",labelsize=20)\n",
    "axes()[:tick_params](\"x\",labelsize=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# writedlm(\"./data/t.txt\", LF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "overallLF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Julia 0.5.0",
   "language": "julia",
   "name": "julia-0.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
