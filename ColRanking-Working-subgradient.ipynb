{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "using PyPlot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "srand(1)\n",
    "\n",
    "# number of users\n",
    "d1 = 20;\n",
    "\n",
    "# number of items\n",
    "d2 = 40;\n",
    "\n",
    "# number of queries\n",
    "n = 600;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# generate the hidden ratings\n",
    "ThetaS = rand(d1,4) * rand(4,d2)\n",
    "\n",
    "# Need to have the sum of rows equaling 0\n",
    "for i = 1:d1\n",
    "    ThetaS[i,:] -= mean(ThetaS[i,:])\n",
    "end\n",
    "\n",
    "# Need to make the Frobenius norm <= 1\n",
    "ThetaS = ThetaS / vecnorm(ThetaS);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y = []\n",
    "X = []\n",
    "\n",
    "for i = 1:n\n",
    "    Xi = zeros(d1, d2)\n",
    "    \n",
    "    lin = rand(1:d1)\n",
    "    c1 = rand(1:d2)\n",
    "    c2 = rand(1:d2)\n",
    "    while c2 == c1\n",
    "        c2 = rand(1:d2)\n",
    "    end\n",
    "    \n",
    "    Xi[lin,c1] = 1\n",
    "    Xi[lin,c2] = -1\n",
    "    Xi = Xi * sqrt(d1 * d2)\n",
    "    \n",
    "    push!(X, Xi)\n",
    "    \n",
    "    if ThetaS[lin,c1] > ThetaS[lin,c2]\n",
    "        push!(y, 1)\n",
    "    else\n",
    "        push!(y, 0)\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nucNorm (generic function with 1 method)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function nucNorm(A)\n",
    "    return sum(svd(A)[2])\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "adjust (generic function with 1 method)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make sure the matrix's rows are centered\n",
    "\n",
    "function adjust(X)\n",
    "    ans = copy(X)\n",
    "    \n",
    "    for i = 1:size(X)[1]\n",
    "        ans[i,:] -= mean(ans[i,:])\n",
    "    end\n",
    "    \n",
    "    return ans\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "obj (generic function with 1 method)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The objective function\n",
    "\n",
    "function obj(Theta, ns)\n",
    "    ans = 0\n",
    "    \n",
    "    for i = 1:ns\n",
    "        ans = ans + log(1 + e^(trace(Theta' * X[i]))) - y[i] * trace(Theta' * X[i])\n",
    "    end\n",
    "    \n",
    "    return ans / ns\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "deltaF (generic function with 1 method)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute the derivative of the objective loss\n",
    "# Theta is our current guess\n",
    "# numSamples represents the number of X's we are considering\n",
    "\n",
    "function deltaF(Theta, ns)\n",
    "    \n",
    "    ans = zeros(d1,d2)\n",
    "    \n",
    "    for i = 1:ns\n",
    "        t = e^trace(Theta' * X[i])\n",
    "        ans = ans + (t / (1 + t) - y[i]) * X[i]\n",
    "    end\n",
    "    \n",
    "    return ans / ns\n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # The proximal function\n",
    "# # return the matrix X that minimizes lambda * ||X||_nuc + 1/(2 lambda_k) || X - V ||_F^2\n",
    "# # equivalent to (lamda*lambda_k) ||X||_nuc + 1/2 || X - V ||_F^2\n",
    "\n",
    "# function prox(lambda, V)\n",
    "    \n",
    "#     A,S,B = svd(V)\n",
    "#     S = max(S - lambda, 0)\n",
    "    \n",
    "#     return adjust(A * diagm(S) * B')\n",
    "    \n",
    "# end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "proxObj (generic function with 1 method)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The proximal objective\n",
    "\n",
    "function proxObj(lambda, X, V)\n",
    "    return lambda * nucNorm(X) + 1 / 2 * norm(X - V)^2\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "prox (generic function with 1 method)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The proximal function\n",
    "# return the matrix X that minimizes lambda * ||X||_nuc + 1/(2 lambda_k) || X - V ||_F^2\n",
    "# equivalent to (lamda * lambda_k) ||X||_nuc + 1/2 || X - V ||_F^2\n",
    "\n",
    "function prox(lambda, V)\n",
    "    \n",
    "    X = adjust(rand(d1,d2))\n",
    "    Xmin = copy(X)\n",
    "    \n",
    "    step = 0.05\n",
    "    eps = 1e-5\n",
    "    numSteps = 0\n",
    "    \n",
    "    while numSteps < 500\n",
    "        numSteps += 1\n",
    "    \n",
    "        # a subgradient of lambda * ||X||_nuc is AB' where X = ASB'\n",
    "        A,_,B = svd(X)\n",
    "        k = rank(X)\n",
    "        A = A[:,1:k]\n",
    "        B = B[:,1:k]\n",
    "\n",
    "        t1 = lambda * A * B'\n",
    "\n",
    "        # the derivative of 1 / 2 || X - V ||_2^2 is (X - V)\n",
    "        t2 = X - V\n",
    "        \n",
    "        newX = X - step * (t1 + t2)\n",
    "        newX = adjust(newX)\n",
    "        \n",
    "        if proxObj(lambda, newX, V) < eps\n",
    "            return newX\n",
    "        end\n",
    "        \n",
    "        if proxObj(lambda, newX, V) < proxObj(lambda, Xmin, V)\n",
    "            Xmin = copy(newX)\n",
    "        end\n",
    "        \n",
    "        X = copy(newX)\n",
    "    end\n",
    "    \n",
    "    return Xmin\n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "checkKKT (generic function with 1 method)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function checkKKT(lamb, Theta, ns)\n",
    "    println(\"Checking KKT conditions\")\n",
    "    \n",
    "    tot = 0\n",
    "    \n",
    "    for i = 1:ns\n",
    "        tot = tot + (e ^ trace(Theta' * X[i]) / (1 + e ^ trace(Theta' * X[i])) - y[i]) * X[i]\n",
    "    end\n",
    "    \n",
    "    tot = tot / ns\n",
    "    \n",
    "    U,S,V = svd(Theta)\n",
    "    k = rank(Theta)\n",
    "    U = U[:,1:k]\n",
    "    V = V[:,1:k]\n",
    "    \n",
    "    tot = tot + lamb * U * V'\n",
    "    \n",
    "    if norm(tot) <= lambda\n",
    "        println(\"GOOD - the norm is smaller than lambda\")\n",
    "    else\n",
    "        println(\"OOPS - the norm is greater than lambda\")\n",
    "    end\n",
    "    \n",
    "    println(norm(U' * tot))\n",
    "    \n",
    "    println(norm(tot * V))\n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### As a sanity check, make sure that our gradient steps indeed decreases obj loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden loss 0.3517101830653011\n",
      "Current loss 4.844326974796623\n",
      "Loss after 1 steps: 3.178521944597706\n",
      "Loss after 2 steps: 2.0764847411472007\n",
      "Loss after 3 steps: 1.3312420421394162\n",
      "Loss after 4 steps: 0.8538984114521607\n",
      "Loss after 5 steps: 0.5260670359854942\n"
     ]
    }
   ],
   "source": [
    "Theta = adjust(rand(d1,d2))\n",
    "\n",
    "println(\"Hidden loss \", obj(ThetaS, n))\n",
    "println(\"Current loss \", obj(Theta, n))\n",
    "\n",
    "for stp = 1:5\n",
    "    alpha = 1.0\n",
    "\n",
    "    newTheta = Theta - alpha * deltaF(Theta, n)\n",
    "    newTheta = adjust(newTheta)\n",
    "\n",
    "    println(\"Loss after \", stp, \" steps: \", obj(newTheta, n))\n",
    "    \n",
    "    Theta = copy(newTheta)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We'll pick a specific number of samples in terms of n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "numSamples = []\n",
    "for den = [3,2,1.5,1.33,1.16,1]\n",
    "    push!(numSamples, convert(Int64, floor(n / den)))\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Let's test out the algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working with 200"
     ]
    }
   ],
   "source": [
    "curTheta = zeros(d1,d2) \n",
    "lambda = 0.1   # the regularization parameter\n",
    "lambda_k = .05   # the step size\n",
    "\n",
    "overallLF = []\n",
    "\n",
    "for ns = numSamples\n",
    "    LF = []\n",
    "    \n",
    "    println(\"working with \", ns, \" samples\")\n",
    "    \n",
    "    maxit = 200\n",
    "    @time for steps = 1:maxit\n",
    "        # retain the old loss\n",
    "        oldLoss = vecnorm(ThetaS - curTheta)^2\n",
    "        \n",
    "        # first, go in the direction of f\n",
    "        V = curTheta - lambda_k * deltaF(curTheta, ns)\n",
    "        \n",
    "#         println(maximum(V), \" \", minimum(V))\n",
    "#         if steps > 350\n",
    "#             println(V)\n",
    "#         end\n",
    "        \n",
    "        # now, perform the proximal step\n",
    "        newTheta = prox(lambda * lambda_k, V)\n",
    "\n",
    "        # some information about runs\n",
    "        if steps % 25 == 0 || steps == maxit\n",
    "            println(\"at iteration \", steps)\n",
    "            \n",
    "            if steps == maxit\n",
    "                println(\"f + g = \", obj(curTheta, ns) + lambda * nucNorm(curTheta))\n",
    "                println(\"f = \", obj(curTheta, ns))\n",
    "                println(\"g = \", lambda * nucNorm(curTheta))\n",
    "                println(\"Loss = \", vecnorm(ThetaS - newTheta)^2)\n",
    "                println()\n",
    "                checkKKT(lambda, newTheta, ns)\n",
    "                println()\n",
    "            end\n",
    "        end\n",
    "\n",
    "        # update the loss array\n",
    "        push!(LF, vecnorm(ThetaS - newTheta)^2)\n",
    "        \n",
    "        # check if the loss is not decreasing anymore\n",
    "        newLoss = vecnorm(ThetaS - newTheta)^2\n",
    "#         if abs(oldLoss - newLoss) < 1e-7\n",
    "#         if newLoss < 0.4\n",
    "#             push!(overallLF, vecnorm(ThetaS - newTheta)^2)\n",
    "            \n",
    "#             println(\"Converged after \", steps, \" iterations\")\n",
    "#             checkKKT(lambda, newTheta, ns)\n",
    "#             println()\n",
    "            \n",
    "#             break\n",
    "#         end\n",
    "        \n",
    "        # if I hit the max number of steps, stop anyway\n",
    "        if steps == maxit\n",
    "            push!(overallLF, vecnorm(ThetaS - newTheta)^2)\n",
    "        end\n",
    "        \n",
    "        # update Theta for the next iteration\n",
    "        curTheta = copy(newTheta)\n",
    "    end\n",
    "    \n",
    "#     dims = convert(Int64, (d1+d2)/2)\n",
    "#     filename = string(\"./data/\", dims, \"-\", ns, \".txt\")\n",
    "#     writedlm(filename, LF)\n",
    "    \n",
    "    println()\n",
    "    println()\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# writedlm(string(\"./data/\", convert(Int64, (d1+d2)/2), \"-final.txt\"), overallLF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plotting the loss function\n",
    "plot(overallLF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# newLF = []\n",
    "# for i = 1:length(LF)\n",
    "#     push!(newLF, log(LF[i]))\n",
    "# end\n",
    "\n",
    "# plot(newLF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# writedlm(\"./data/t.txt\", LF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "overallLF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Julia 0.5.0",
   "language": "julia",
   "name": "julia-0.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
