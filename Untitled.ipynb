{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "srand(123)\n",
    "\n",
    "# number of users\n",
    "d1 = 3;\n",
    "\n",
    "# number of items\n",
    "d2 = 5; \n",
    "\n",
    "# number of queries\n",
    "n = 20;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ThetaS = rand(d1, d2);\n",
    "\n",
    "# Need to have the sum of rows equaling 0\n",
    "for i = 1:d1\n",
    "    ThetaS[i,:] -= mean(ThetaS[i,:])\n",
    "end\n",
    "\n",
    "# Need to make the Frobenius norm < 1\n",
    "ThetaS = ThetaS / vecnorm(ThetaS);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y = []\n",
    "X = []\n",
    "\n",
    "for i = 1:n\n",
    "    Xi = zeros(d1, d2)\n",
    "    \n",
    "    lin = rand(1:d1)\n",
    "    c1 = rand(1:d2)\n",
    "    c2 = rand(1:d2)\n",
    "    while c2 == c1\n",
    "        c2 = rand(1:d2)\n",
    "    end\n",
    "    \n",
    "    Xi[lin,c1] = 1\n",
    "    Xi[lin,c2] = -1\n",
    "    Xi = Xi * sqrt(d1 * d2)\n",
    "    \n",
    "    push!(X, Xi)\n",
    "    \n",
    "    if ThetaS[lin,c1] > ThetaS[lin,c2]\n",
    "        push!(y, 1)\n",
    "    else\n",
    "        push!(y, 0)\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nucNorm (generic function with 1 method)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function nucNorm(A)\n",
    "    return sum(svd(A)[2])\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "loss (generic function with 1 method)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The loss function\n",
    "\n",
    "function loss(Theta)\n",
    "    ans = 0\n",
    "    \n",
    "    for i = 1:n\n",
    "        ans = ans + log(1 + e^(trace(Theta' * X[i])) - y[i] * trace(Theta' * X[i]))\n",
    "    end\n",
    "    \n",
    "    return ans / n\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0789259523597532"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss(ThetaS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "deltaF (generic function with 1 method)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute the derivative of the loss function. This will be the 'v' in the proximal step\n",
    "\n",
    "function deltaF(Theta)\n",
    "    \n",
    "    ans = zeros(d1,d2)\n",
    "    \n",
    "    for i = 1:n\n",
    "        t1 = 1 / (1 + e^trace(Theta' * X[i]) - y[i] * trace(Theta' * X[i]))\n",
    "        t2 = e^trace(Theta' * X[i]) * X[i]\n",
    "        t3 = y[i] * X[i]\n",
    "        \n",
    "        ans = ans + t1 * (t2 + t3)\n",
    "    end\n",
    "    \n",
    "    return ans / n\n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal loss 1.0789259523597532\n",
      "Current loss 1.4045155344420006\n",
      "Loss after 1 steps: 1.3629748516638307\n",
      "Loss after 2 steps: 1.3204069290598157\n",
      "Loss after 3 steps: 1.2771168392712426\n",
      "Loss after 4 steps: 1.2335614189422206\n",
      "Loss after 5 steps: 1.1903395311231104\n",
      "Loss after 6 steps: 1.1481374568198905\n",
      "Loss after 7 steps: 1.107668676788799\n",
      "Loss after 8 steps: 1.0696240907535999\n",
      "Loss after 9 steps: 1.034616307445256\n",
      "Loss after 10 steps: 1.0031000802770063\n",
      "Loss after 11 steps: 0.975289271363925\n",
      "Loss after 12 steps: 0.9511219219750622\n",
      "Loss after 13 steps: 0.9303029199807783\n",
      "Loss after 14 steps: 0.9124004969076775\n",
      "Loss after 15 steps: 0.8969464459186269\n",
      "Loss after 16 steps: 0.8835056262299451\n",
      "Loss after 17 steps: 0.8717086453403173\n",
      "Loss after 18 steps: 0.8612580480065446\n",
      "Loss after 19 steps: 0.8519208602120125\n",
      "Loss after 20 steps: 0.8435165317486014\n",
      "Loss after 21 steps: 0.8359049788308788\n",
      "Loss after 22 steps: 0.8289765368354409\n",
      "Loss after 23 steps: 0.8226441590803747\n",
      "Loss after 24 steps: 0.8168376035070404\n",
      "Loss after 25 steps: 0.811499190761141\n",
      "Loss after 26 steps: 0.8065807371538487\n",
      "Loss after 27 steps: 0.8020413408069196\n",
      "Loss after 28 steps: 0.7978457781964166\n",
      "Loss after 29 steps: 0.7939633345016424\n",
      "Loss after 30 steps: 0.7903669417693729\n",
      "Loss after 31 steps: 0.7870325358729567\n",
      "Loss after 32 steps: 0.7839385696275939\n",
      "Loss after 33 steps: 0.7810656380252863\n",
      "Loss after 34 steps: 0.7783961845968568\n",
      "Loss after 35 steps: 0.7759142670371655\n",
      "Loss after 36 steps: 0.7736053666186742\n",
      "Loss after 37 steps: 0.7714562303950248\n",
      "Loss after 38 steps: 0.7694547383378288\n",
      "Loss after 39 steps: 0.7675897897586351\n",
      "Loss after 40 steps: 0.7658512049241358\n",
      "Loss after 41 steps: 0.7642296388714331\n",
      "Loss after 42 steps: 0.7627165052080841\n",
      "Loss after 43 steps: 0.7613039082342243\n",
      "Loss after 44 steps: 0.7599845821182829\n",
      "Loss after 45 steps: 0.7587518361406929\n",
      "Loss after 46 steps: 0.7575995052245268\n",
      "Loss after 47 steps: 0.756521905121357\n",
      "Loss after 48 steps: 0.7555137917311072\n",
      "Loss after 49 steps: 0.7545703241176329\n",
      "Loss after 50 steps: 0.7536870308452364\n"
     ]
    }
   ],
   "source": [
    "Theta = rand(d1,d2)\n",
    "for i = 1:d1\n",
    "    Theta[i,:] -= mean(Theta[i,:])\n",
    "end\n",
    "Theta = Theta / vecnorm(Theta)\n",
    "\n",
    "println(\"Optimal loss \", loss(ThetaS))\n",
    "println(\"Current loss \", loss(Theta))\n",
    "\n",
    "\n",
    "for stp = 1:50\n",
    "    alpha = 0.05\n",
    "    der = deltaF(Theta)\n",
    "\n",
    "    newTheta = Theta - alpha * der\n",
    "    for i = 1:d1\n",
    "        newTheta[i,:] -= mean(newTheta[i,:])\n",
    "    end\n",
    "    newTheta = newTheta / vecnorm(newTheta)\n",
    "\n",
    "    println(\"Loss after \", stp, \" steps: \", loss(newTheta))\n",
    "    \n",
    "    Theta = copy(newTheta)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Julia 0.5.0",
   "language": "julia",
   "name": "julia-0.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
